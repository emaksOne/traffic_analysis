{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"video_process_example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PmJV6fmVocyd","colab_type":"code","outputId":"833428c6-f36c-4596-a6fe-eed68b29cad8","executionInfo":{"status":"ok","timestamp":1575742983773,"user_tz":-120,"elapsed":32872,"user":{"displayName":"Mr Meeseeks Look at me","photoUrl":"","userId":"05531505537449859454"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["#uncomment in case of google colab\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O4_k8Uwi9qAY","colab_type":"code","outputId":"5b7918ea-f1e3-41d4-ae36-1ae1c6cc57bf","executionInfo":{"status":"ok","timestamp":1575742994121,"user_tz":-120,"elapsed":7808,"user":{"displayName":"Mr Meeseeks Look at me","photoUrl":"","userId":"05531505537449859454"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["#uncomment in case of google colab\n","\n","# !pip install filterpy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting filterpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/ac8914360460fafa1990890259b7fa5ef7ba4cd59014e782e4ab3ab144d8/filterpy-1.4.5.zip (177kB)\n","\r\u001b[K     |█▉                              | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 71kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 81kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 153kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 163kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 174kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 6.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.17.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.3.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from filterpy) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.6.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.4.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (0.10.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->filterpy) (42.0.1)\n","Building wheels for collected packages: filterpy\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-cp36-none-any.whl size=110453 sha256=4db3f894321f72bb920ad8029b4925f8d6f87eccac56c2c9880ba8e9a81451d4\n","  Stored in directory: /root/.cache/pip/wheels/c3/0c/dd/e92392c3f38a41371602d99fc77d6c1d42aadbf0c6afccdd02\n","Successfully built filterpy\n","Installing collected packages: filterpy\n","Successfully installed filterpy-1.4.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IPmXc-TVof7g","colab_type":"code","colab":{}},"source":["#uncomment in case of google colab\n","\n","# import os\n","# PATH_TO_FILE = '/content/drive/My Drive/Development/traffic_analysis'\n","# os.chdir(PATH_TO_FILE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UjuJ66NmqrBN","colab_type":"code","outputId":"24561ed8-7007-4b1c-dd3a-67607cdf41e6","executionInfo":{"status":"ok","timestamp":1575743009296,"user_tz":-120,"elapsed":8433,"user":{"displayName":"Mr Meeseeks Look at me","photoUrl":"","userId":"05531505537449859454"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["import colorsys\n","import os\n","from timeit import default_timer as timer\n","import numpy as np\n","import tensorflow as tf\n","from keras import backend as K\n","from keras.models import load_model\n","from keras.layers import Input, Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Model\n","from keras.regularizers import l2\n","import cv2\n","import os\n","from keras.utils import multi_gpu_model\n","from functools import reduce, wraps\n","from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n","\n","from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n","from yolo3.utils import letterbox_image\n","from sort.sort import Sort\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","np.set_printoptions(precision=3)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n","  DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YJ3-Hog5qfQF","colab_type":"code","cellView":"code","colab":{}},"source":["#@title yolo\n","\n","class YOLO(object):\n","    _defaults = {\n","        \"model_path\": 'model_data/yolo.h5',\n","        \"anchors_path\": 'model_data/yolo_anchors.txt',\n","        \"classes_path\": 'model_data/coco_classes.txt',\n","        \"score\" : 0.3,\n","        \"iou\" : 0.45,\n","        \"model_image_size\" : (416, 416),\n","        \"gpu_num\" : 1,\n","        \"text_size\" : 2\n","    }\n","\n","    @classmethod\n","    def get_defaults(cls, n):\n","        if n in cls._defaults:\n","            return cls._defaults[n]\n","        else:\n","            return \"Unrecognized attribute name '\" + n + \"'\"\n","\n","    def __init__(self, **kwargs):\n","        self.__dict__.update(self._defaults) # set up default values\n","        self.__dict__.update(kwargs) # and update with user overrides\n","        self.class_names = self._get_class()\n","        self.anchors = self._get_anchors()\n","\n","        self.sess = K.get_session()\n","        self.boxes, self.scores, self.classes = self.generate()\n","\n","    def _get_class(self):\n","        classes_path = os.path.expanduser(self.classes_path)\n","        with open(classes_path) as f:\n","            class_names = f.readlines()\n","        class_names = [c.strip() for c in class_names]\n","        return class_names\n","\n","    def _get_anchors(self):\n","        anchors_path = os.path.expanduser(self.anchors_path)\n","        with open(anchors_path) as f:\n","            anchors = f.readline()\n","        anchors = [float(x) for x in anchors.split(',')]\n","        return np.array(anchors).reshape(-1, 2)\n","\n","    def generate(self):\n","        model_path = os.path.expanduser(self.model_path)\n","        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n","\n","        # Load model, or construct model and load weights.\n","        num_anchors = len(self.anchors)\n","        num_classes = len(self.class_names)\n","        is_tiny_version = num_anchors==6 # default setting\n","        try:\n","            self.yolo_model = load_model(model_path, compile=False)\n","        except:\n","            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n","                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n","            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n","        else:\n","            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n","                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n","                'Mismatch between model and given anchor and class sizes'\n","\n","        print('{} model, anchors, and classes loaded.'.format(model_path))\n","\n","        # Generate colors for drawing bounding boxes.\n","        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n","                      for x in range(len(self.class_names))]\n","        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","        self.colors = list(\n","            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n","                self.colors))\n","        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n","        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n","        np.random.seed(None)  # Reset seed to default.\n","\n","        # Generate output tensor targets for filtered bounding boxes.\n","        self.input_image_shape = K.placeholder(shape=(2, ))\n","        if self.gpu_num>=2:\n","            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n","        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n","                len(self.class_names), self.input_image_shape,\n","                score_threshold=self.score, iou_threshold=self.iou)\n","        return boxes, scores, classes\n","\n","    def predict(self, image):\n","        if self.model_image_size != (None, None):\n","            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n","            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n","            boxed_image = letterbox_image(np.copy(image), tuple(reversed(self.model_image_size)))\n","            image_data = boxed_image\n","\n","        out_boxes, out_scores, out_classes = self.sess.run(\n","            [self.boxes, self.scores, self.classes],\n","            feed_dict={\n","                self.yolo_model.input: image_data,\n","                self.input_image_shape: [image.shape[0], image.shape[1]],#[image.size[1], image.size[0]],\n","                K.learning_phase(): 0\n","            })\n","        \n","        return out_boxes, out_scores, out_classes\n","\n","    def draw_boxes(self, image, out_boxes, out_scores, out_classes, indexes_to_highlite, ids, class_count, line_y, thicknessFactor = 4):\n","        image_h = image.shape[0]\n","        image_w = image.shape[1]\n","        white_color = (255, 255, 255)\n","        thickness = 1\n","        fontScale=1\n","        \n","        total = int(sum(class_count.values()))\n","        items_cnt = ['{}: {}'.format(self.class_names[key], int(val)) for key, val in class_count.items()]\n","        items_cnt_str = ', '.join(items_cnt)\n","        whole_count_text = f'total: {total}, {items_cnt_str}'\n","        cv2.putText(image, whole_count_text, (50, image_h - 50), cv2.FONT_HERSHEY_SIMPLEX, \n","                    2*fontScale, white_color, int(thicknessFactor*thickness))\n","       \n","        #for i, obj_id in reversed(list(enumerate(ids))):\n","        for i, obj_id in enumerate(ids):\n","            predicted_class = self.class_names[out_classes[i]]\n","            box = out_boxes[i]\n","            score = out_scores[i]\n","\n","            label = '{} {:.2f}'.format(predicted_class, score)\n","\n","            top, left, bottom, right = box\n","            top = max(0, np.floor(top + 0.5).astype('int32'))\n","            left = max(0, np.floor(left + 0.5).astype('int32'))\n","            bottom = min(image.shape[0], np.floor(bottom + 0.5).astype('int32'))\n","            right = min(image.shape[1], np.floor(right + 0.5).astype('int32'))\n","\n","            mid_h = (bottom-top)/2+top\n","            mid_v = (right-left)/2+left\n","            white_color = (255,255,255)\n","            black_color = (0,0,0)\n","            \n","            if mid_h >= line_y and i in indexes_to_highlite:\n","                cv2.rectangle(image, (left, top), (right, bottom), self.colors[out_classes[i]], int(thicknessFactor*thickness))\n","                # put text above rectangle\n","                cv2.putText(image, label, (left, top-2), cv2.FONT_HERSHEY_SIMPLEX, fontScale, white_color, 2)\n","            else:\n","                # put object rectangle\n","                cv2.rectangle(image, (left, top), (right, bottom), white_color, thickness)   \n","\n","        return image\n","\n","    def close_session(self):\n","        self.sess.close()\n","\n","    def get_class_names(self):\n","        return self.class_names"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XaWxcaCFLGa","colab_type":"code","cellView":"code","colab":{}},"source":["#@title MOT\n","DEFAULT_MAX_DISTANCE_BETWEEN_POINTS = 60 \n","DEFAULT_WARMUP_FRAMES = 8\n","DEFAUTL_MIN_HITS = 3\n","DEFAULT_MAX_AGE = 10\n","class MOT():\n","\n","    def __init__(self, **kwargs):\n","        print(kwargs)\n","        self._state = {}\n","        self._statistics = []\n","        self._class_count = dict(zip(kwargs['class_ids'], np.zeros(len(kwargs['class_ids']))))\n","        # if distance between centers of two bboxes is less than _max_distance then object is staying\n","        self._max_distance = kwargs['max_distance'] if 'max_distance' in kwargs else DEFAULT_MAX_DISTANCE_BETWEEN_POINTS\n","\n","        # after _warmup_frames we start to compare bbox's centers for one tracked object\n","        self._warmup_frames = kwargs['warmup_frames'] if 'warmup_frames' in kwargs else DEFAULT_WARMUP_FRAMES\n","\n","        self._line_y = kwargs['line_y'] if 'line_y' in kwargs else 0\n","\n","        min_hits = kwargs['min_hits'] if 'min_hits' in kwargs else DEFAUTL_MIN_HITS\n","        max_age = kwargs['max_age'] if 'max_age' in kwargs else DEFAULT_MAX_AGE\n","        #self.display_config()\n","        self._mot_tracker = Sort(max_age, min_hits)\n","\n","    def display_config(self):\n","        print('line_y')\n","        print(self._line_y)\n","        print('warmup_frames')\n","        print(self._warmup_frames)\n","        print('max_distance')\n","        print(self._max_distance)\n","\n","    def update_state(self, boxes, scores, classes, timestamp):\n","        dets = np.array(boxes)\n","        dets = np.hstack((dets, scores.reshape(scores.shape[0],1)))\n","        trackers, matched, unmatched_dets = self._mot_tracker.update(dets)\n","        boxes, scores, classes, ids = self.mot_output_postprocess(trackers, boxes, scores, classes, matched, unmatched_dets)\n","        filtered_inds, object_crossed = self.filter_moving_obj_ids(boxes, scores, classes, ids)\n","\n","        if len(object_crossed) > 0:\n","             self._statistics.append({'timestamp': timestamp, 'class_count': self._class_count.copy(), 'objects': object_crossed})\n","     \n","        scores = scores.reshape((scores.shape[0],))\n","        classes = classes.reshape((classes.shape[0],))\n","        classes = classes.astype(int)\n","\n","        return filtered_inds, boxes, scores, classes, ids\n","\n","    def filter_moving_obj_ids(self, boxes, scores, classes, ids):\n","        filtered_inds = set()\n","        object_crossed = []\n","        for i, obj_id in enumerate(ids):\n","            top, left, bottom, right = boxes[i]\n","            w = right - left\n","            h = bottom - top\n","            x_c = left + w/2\n","            y_c = top + h/2\n","            if obj_id in self._state:\n","                state_obj = self._state[obj_id]\n","                if state_obj['frame_num'] <  self._warmup_frames:\n","                    state_obj['frame_num']+=1\n","                    self._state[obj_id] = state_obj\n","                else:\n","                    if not self.is_close([x_c, y_c], state_obj['origin_pos']) and \\\n","                        state_obj['origin_pos'][1] < y_c:\n","                        filtered_inds.add(i)\n","                \n","                        if not state_obj['already_counted']:\n","                            origin_y = state_obj['origin_pos'][1]\n","                        \n","                            if state_obj['origin_pos'][1] < self._line_y and y_c >= self._line_y:\n","                                self._class_count[classes[i]] += 1\n","                                state_obj['already_counted'] = True\n","                                self._state[obj_id] = state_obj\n","                                object_crossed.append([classes[i], scores[i]])\n","                    \n","            else:\n","                new_obj = {'frame_num': 1, 'origin_pos': [x_c, y_c], 'already_counted': False}\n","                self._state[obj_id] = new_obj\n","\n","        return filtered_inds, object_crossed\n","\n","    def mot_output_postprocess(self, trackers, boxes, scores, classes, matched, unmatched_dets):\n","        trackers =trackers[::-1]\n","      \n","        matched = matched[matched[:,1].argsort()]\n","        new_ind = matched[:,0]\n","\n","        boxes_unmathced = np.empty((0,4))\n","        scores_unmathced = np.empty((0,1))\n","        classes_unmathced = np.empty((0,1))\n","        if len(unmatched_dets) > 0:\n","            boxes_unmathced = boxes.take(unmatched_dets, axis = 0)\n","            scores_unmathced = scores.take(unmatched_dets, axis = 0)\n","            classes_unmathced = classes.take(unmatched_dets, axis = 0)\n","\n","        boxes = trackers[:, 0:4]\n","        scores = scores.take(new_ind, axis = 0)\n","        classes = classes.take(new_ind, axis = 0)\n","       \n","        ids = trackers[:, 4]\n","\n","        scores = scores.reshape(-1,1)\n","        classes = classes.reshape(-1,1)\n","        scores_unmathced = scores_unmathced.reshape(-1,1)\n","        classes_unmathced = classes_unmathced.reshape(-1,1)\n","\n","        boxes = np.vstack((boxes, boxes_unmathced))\n","        scores = np.vstack((scores, scores_unmathced))\n","        classes = np.vstack((classes, classes_unmathced))\n","        \n","        scores = scores.reshape((-1,))\n","        classes = classes.reshape((-1,))\n","\n","        return boxes, scores, classes, ids\n","        \n","    def get_class_count(self):\n","        return self._class_count\n","    \n","    def get_statistics(self):\n","        return self._statistics\n","\n","    def is_close(self, point_1, point_2):\n","        dist = np.linalg.norm(np.array(point_1)-np.array(point_2))\n","        return dist < self._max_distance\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3THVfsu3dgc","colab_type":"code","colab":{}},"source":["def draw_line(image, line_y, color, thickness):\n","    x1 = 0\n","    y1 = int(line_y)\n","    x2 = image.shape[1]\n","    y2 = int(line_y)\n","    cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n","    return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-guP_guU48DU","colab_type":"code","outputId":"67371c7c-ca28-461b-ab99-d5fcf4a929ed","executionInfo":{"status":"ok","timestamp":1575743134378,"user_tz":-120,"elapsed":18864,"user":{"displayName":"Mr Meeseeks Look at me","photoUrl":"","userId":"05531505537449859454"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# config ={\"model_path\":'model_data/trained_weights_stage_1.h5',\n","#         \"classes_path\": 'model_data/vehicle_test_classes.txt'}\n","# yolo = YOLO(**config)\n","yolo = YOLO()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["model_data/yolo.h5 model, anchors, and classes loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BiOXp0wf5kNt","colab_type":"code","colab":{}},"source":["# use to filter vehicle classes when use coco weights (80 classess)\n","def filter_vehicle_classes(boxes, scores, classes):\n","    vehicle_classes = {2, 5, 7}\n","    inds = np.arange(classes.shape[0])\n","    filtered_inds = [i for i in inds if classes[i] in vehicle_classes]\n","   \n","    boxes = boxes[filtered_inds]\n","    scores = scores[filtered_inds]\n","    classes = classes[filtered_inds]\n","\n","    return boxes, scores, classes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgMVXPHQnquW","colab_type":"code","colab":{}},"source":["def detect_video(yolo, input_video, output_video, h_reltive_pos, coco_weights=False):\n","    vid = cv2.VideoCapture(input_video)\n","    if not vid.isOpened():\n","        raise IOError(\"Couldn't open video\")\n","\n","    video_FourCC    = int(vid.get(cv2.CAP_PROP_FOURCC))\n","    video_fps       = vid.get(cv2.CAP_PROP_FPS)\n","    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n","                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","\n","    class_names = yolo.get_class_names()\n","    class_ids = np.arange(len(class_names))\n","    if coco_weights:\n","        class_names = ['car', 'bus', 'truck']\n","        class_ids = [2,5,7]\n","\n","    line_y = video_size[1]*h_reltive_pos\n","    config = {'min_hits': 3, 'max_age':10, 'line_y': line_y,\n","              'max_distance': 90, 'warmup_frames': 10,\n","              'class_ids': class_ids}\n","    mot_tracker = MOT(**config)\n","\n","    print(\"info: \", output_video, video_FourCC, video_fps, video_size)\n","    out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'MJPG'), video_fps, video_size)\n","   \n","    accum_time = 0\n","    curr_fps = 0\n","    fps = \"FPS: ??\"\n","    prev_time = timer()\n","    nb_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print(f'frames num = {nb_frames}')\n","    for i in range(nb_frames):\n","        return_value, frame = vid.read()\n","        boxes, scores, classes = yolo.predict(frame)\n","        \n","        if coco_weights:\n","            boxes, scores, classes = filter_vehicle_classes(boxes, scores, classes)\n","\n","        filtered_inds, boxes, scores, classes, ids = mot_tracker.update_state(boxes, scores, classes, timestamp=int(i//video_fps))\n","\n","        class_count = mot_tracker.get_class_count()\n","        image = yolo.draw_boxes(frame, boxes, scores, classes, filtered_inds, ids, class_count, line_y, 5)\n","        image = draw_line(image, line_y, color=(255,255,255), thickness=4)\n","\n","        curr_time = timer()\n","        exec_time = curr_time - prev_time\n","        prev_time = curr_time\n","        accum_time = accum_time + exec_time\n","        curr_fps = curr_fps + 1\n","        if accum_time > 1:\n","            accum_time = accum_time - 1\n","            fps = \"FPS: \" + str(curr_fps)\n","            curr_fps = 0\n","        if i % 50 == 0:\n","            print(f'fps = {fps}')\n","        out.write(np.uint8(image))\n","    \n","    statistics = mot_tracker.get_statistics()\n","\n","    vid.release()\n","    out.release()\n","\n","    #write statistics to file\n","    statistics_path = str(output_video)[:-4] + '_statistics.txt'\n","    with open(statistics_path, 'w') as file:\n","        file.write(f'input video: {input_video}')\n","        file.write('\\n')\n","        file.write(f'output video: {output_video}')\n","        file.write('\\n')\n","        file.write(f'line position: {h_reltive_pos}')\n","        file.write('\\n')\n","        for stat in statistics:\n","            timestamp = stat['timestamp']\n","            class_count = stat['class_count']\n","            total = int(sum(class_count.values()))\n","            if coco_weights:\n","                helper_dict = {2:0, 5:1, 7:2}\n","                items_cnt = ['{}: {}'.format(class_names[helper_dict[key]], int(val)) for key, val in class_count.items()]\n","                objects_str = '; '.join(list(map(lambda x: 'class: {0}; pred: {1}'.format(class_names[helper_dict[x[0]]], x[1]),\n","                                                 stat['objects'])))\n","            else:\n","                items_cnt = ['{}: {}'.format(class_names[key], int(val)) for key, val in class_count.items()]\n","                objects_str = '; '.join(list(map(lambda x: f'class: {int(x[0])}; pred: {x[1]}', stat['objects'])))\n","            items_cnt_str = ', '.join(items_cnt)\n","            whole_count_text = f'total: {total}, {items_cnt_str}'\n","            line = f'timestamp: {timestamp} sec.;    {whole_count_text};    objects: {objects_str}'\n","            file.write(line)\n","            file.write('\\n')\n","\n","            \n","    #yolo.close_session()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nV4Bsp5m8NWi","colab_type":"code","colab":{}},"source":["input_video = 'data/example2.mp4'\n","output_video = 'data/example2_proc.mp4'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpWZafyYpQ9r","colab_type":"code","colab":{}},"source":["h_reltive_pos = 0.33 # position of crossed line\n","detect_video(yolo, input_video, output_video, h_reltive_pos, coco_weights=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjZo7X59p9lg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}